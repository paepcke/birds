

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>result_analysis package &mdash; Birdsong  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Birdsong
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">result_analysis package</a><ul>
<li><a class="reference internal" href="#subpackages">Subpackages</a></li>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-result_analysis.charting">result_analysis.charting module</a></li>
<li><a class="reference internal" href="#module-result_analysis">Module contents</a></li>
</ul>
</li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Birdsong</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>result_analysis package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/source/result_analysis.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="result-analysis-package">
<h1>result_analysis package<a class="headerlink" href="#result-analysis-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="result_analysis.tests.html">result_analysis.tests package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="result_analysis.tests.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="result_analysis.tests.html#module-result_analysis.tests.test_charting">result_analysis.tests.test_charting module</a></li>
<li class="toctree-l2"><a class="reference internal" href="result_analysis.tests.html#module-result_analysis.tests">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-result_analysis.charting">
<span id="result-analysis-charting-module"></span><h2>result_analysis.charting module<a class="headerlink" href="#module-result_analysis.charting" title="Permalink to this headline">¶</a></h2>
<p>Created on May 6, 2021</p>
<p>&#64;author: paepcke</p>
<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.BestOperatingPoint">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">BestOperatingPoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f1_score</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precision</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.BestOperatingPoint" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>Instances hold information about the 
optimal point on a PR curve. That is
the decision threshold where the corresponding
recall/precision yields the maximum F1 score</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">CELL_LABELING</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.CELL_LABELING" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING.ALWAYS">
<span class="sig-name descname"><span class="pre">ALWAYS</span></span><em class="property"> <span class="pre">=</span> <span class="pre">0</span></em><a class="headerlink" href="#result_analysis.charting.CELL_LABELING.ALWAYS" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING.AUTO">
<span class="sig-name descname"><span class="pre">AUTO</span></span><em class="property"> <span class="pre">=</span> <span class="pre">10</span></em><a class="headerlink" href="#result_analysis.charting.CELL_LABELING.AUTO" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING.CONF_MATRIX_CELL_LABEL_LIMIT">
<span class="sig-name descname"><span class="pre">CONF_MATRIX_CELL_LABEL_LIMIT</span></span><em class="property"> <span class="pre">=</span> <span class="pre">10</span></em><a class="headerlink" href="#result_analysis.charting.CELL_LABELING.CONF_MATRIX_CELL_LABEL_LIMIT" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING.DIAGONAL">
<span class="sig-name descname"><span class="pre">DIAGONAL</span></span><em class="property"> <span class="pre">=</span> <span class="pre">2</span></em><a class="headerlink" href="#result_analysis.charting.CELL_LABELING.DIAGONAL" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.CELL_LABELING.NEVER">
<span class="sig-name descname"><span class="pre">NEVER</span></span><em class="property"> <span class="pre">=</span> <span class="pre">1</span></em><a class="headerlink" href="#result_analysis.charting.CELL_LABELING.NEVER" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.Charter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">Charter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">actions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.DIV_BY_ZERO">
<span class="sig-name descname"><span class="pre">DIV_BY_ZERO</span></span><em class="property"> <span class="pre">=</span> <span class="pre">0</span></em><a class="headerlink" href="#result_analysis.charting.Charter.DIV_BY_ZERO" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.calc_conf_matrix_norm">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">calc_conf_matrix_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conf_matrix</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.calc_conf_matrix_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates a normalized confusion matrix.
Normalizes by the number of samples that each 
species contributed to the confusion matrix.
Each cell in the returned matrix will be a
percentage of the number of samples for the
row. If no samples were present for a
particular class, the respective cells will
contain -1.</p>
<p>It is assumed that rows correspond to the classes 
truth labels, and cols to the classes of the
predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>conf_matrix</strong> (<em>{pd.DataFrame</em><em>[</em><em>int</em><em>] </em><em>| np.array | torch.Tensor}</em>) – confusion matrix to normalize</p>
</dd>
</dl>
<dl class="simple">
<dt>:returned a new confusion matrix with cells replaced</dt><dd><p>by the percentage of time that cell’s prediction
was made. Cells of classes without any samples in
the dataset will contain -1</p>
</dd>
</dl>
<p>:rtype matches input type</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.compute_binary_pr_curve">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">compute_binary_pr_curve</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.compute_binary_pr_curve" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the recall (x-axis) and precision (y-axis)
values of a PR curve, its average precision (AP),
and optimal threshold with corresponding f1, precision, 
and recall values</p>
<p>The optimal threshold’s prec and rec yield the
maximum f1 score. Information provided in the 
BestOperatingPoint instance that is part of this
method’s return:</p>
<blockquote>
<div><p>threshold
f1
prec
rec</p>
</div></blockquote>
<p>The result is packaged as a CurveSpecification
that contains:</p>
<blockquote>
<div><p>best_op_pt
precisions
recalls
thresholds
avg_prec’</p>
</div></blockquote>
<p>Procedure:</p>
<p>A prec/rec point is computed for each 
threshold point.</p>
<p>Works for binary classification.
But can use sklearn’s label_binaries to compute 
separate curves for each class 
(see compute_multiclass_pr_curves())</p>
<p>Differs from sklearn.precision_recall_curve() in
that the sklearn method does not take a list
of thresholds.</p>
<p>Example:
(preds are probabilities, but they</p>
<blockquote>
<div><p>are from one class, different samples.
So dont’ add to 1):</p>
<blockquote>
<div><blockquote>
<div><p>labels  = [1,1,0,1]
preds  = [0.2, 0.4, 0.1, 0.2]</p>
</div></blockquote>
<p>thresholds  = [0.3, 0.7]</p>
<dl class="simple">
<dt>The predictions are turned into decisions like this:</dt><dd><p>preds_decided_0.3 = [0, 1, 0, 0]
preds_decided_0.5 = [0, 0, 0, 0]</p>
</dd>
</dl>
<p>Two prec and rec computations are executed:</p>
<blockquote>
<div><blockquote>
<div><dl class="simple">
<dt>pr0:  prec and rec from [1, 1, 0, 1] </dt><dd><p>[0, 1, 0, 0]</p>
</dd>
<dt>pr1:  prec and rec from [1, 1, 0, 1]</dt><dd><p>[0, 0, 0, 0]</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>resulting in:</dt><dd><p>precs = [p0, p1]
recs  = [r0, r1]</p>
</dd>
</dl>
</div></blockquote>
<p>F1 values fs = [f0, f1] are computed for p0/r0,
and p1/r1. The position idx (argmax) of 
the highest f1 is determined.</p>
<dl>
<dt>best_op_pt = {</dt><dd><blockquote>
<div><p>‘threshold’ : thresholds[idx], 
‘f1’        : fs[idx], 
‘prec’      : precs[idx] 
‘rec’       : recs[idx]</p>
</div></blockquote>
<p>}</p>
</dd>
</dl>
<p>Finally the average precision (AP) is
computed. It derives from precs and recs:</p>
<p>for k=0 to k=n-1
AP = sum_ovr_k((recs_k - recs_[k-1]) * preds_k)</p>
<p>where n is number of thresholds, 
recs_k and precs_k are precision and 
recall at the kth threshold. By definition,
preds_n = 1, recs_n = 0.</p>
<dl class="simple">
<dt>Returned: a CurveSpecification instance</dt><dd><dl class="simple">
<dt>containing:</dt><dd><p>best_op_pt
precisions
recalls
avg_prec</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>[</em><em>int | str</em><em>]</em>) – integer binary class labels.
Exs.: [1,1,0,0], [‘yes’, ‘yes’, ‘no’, ‘yes’]</p></li>
<li><p><strong>preds</strong> (<em>[</em><em>float | int</em><em>]</em>) – predictions output from a classifier.
May be floats or integers</p></li>
<li><p><strong>class_id</strong> (<em>{int | str}</em>) – ID of target class for which this
curve is being constructed</p></li>
<li><p><strong>thresholds</strong> (<em>[</em><em>float | int</em><em>]</em>) – list of decision thresholds to
decide whether preds are one class or the other.
If None, uses [0.2, 0.4, 0.6, 0.8, 1]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>CurveSpecification instances with optimal 
operating point, and lists with prec and recall 
ready for drawing a PR curve</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#result_analysis.charting.CurveSpecification" title="result_analysis.charting.CurveSpecification">CurveSpecification</a></p>
</dd>
</dl>
<dl class="simple">
<dt>:raises ValueError if labels hold more than </dt><dd><p>two distinct values</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.compute_confusion_matrix">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">compute_confusion_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">truth_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">predicted_class_ids</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.compute_confusion_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Example Confustion matrix for 16 samples,
in 3 classes:</p>
<blockquote>
<div><blockquote>
<div><p>C_1-pred, C_2-pred, C_3-pred</p>
</div></blockquote>
<p>C_1-true        3         1        0
C_2-true        2         6        1
C_3-true        0         0        3</p>
</div></blockquote>
<p>The number of classes is needed to let 
sklearn to know even about classes that were not
encountered.</p>
<p>Assumption: self.class_names contains list 
of class names, i.e. not the numeric IDs, but the
ones to use when labeling the matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>truth_labels</strong> (<em>[</em><em>int</em><em>]</em>) – truth labels as list of class ids</p></li>
<li><p><strong>predicted_class_ids</strong> (<em>[</em><em>int</em><em>]</em>) – list of class_ids that were
predicted, in same order as truth_labels</p></li>
<li><p><strong>class_names</strong> (<em>[</em><em>str</em><em>]</em>) – list of class names as known to the
user, i.e. not the numeric class ints. But the names
to use as matrix labels in class id order!</p></li>
<li><p><strong>normalize</strong> (<em>bool</em>) – whether or not to normalize ROWS
to add to 1. I.e. turn cells into percentages</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a dataframe of the confusion matrix; columns 
and rows (i.e. index) set to class ids</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.compute_multiclass_pr_curves">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">compute_multiclass_pr_curves</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">truth_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.2,</span> <span class="pre">0.4,</span> <span class="pre">0.6,</span> <span class="pre">0.8]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.compute_multiclass_pr_curves" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the data needed to draw
a family of PR curves for the results
of multiclass classifier output.</p>
<p>Returns a dict of the constituent 
single-class curve specs, and a
mean average precision (mAP) score
for all curves combined.</p>
<p>Each result dict maps a class ID
to all info needed for one of the
curves:</p>
<blockquote>
<div><dl class="simple">
<dt>1:</dt><dd><dl class="simple">
<dt>{‘best_op_pt’<span class="classifier">best_operating_pt,</span></dt><dd><p>‘precisions’ : precisions,
‘recalls’    : recalls,
‘thresholds’ : thresholds,
‘avg_prec’   : avg_precision
}</p>
</dd>
</dl>
</dd>
<dt>2:</dt><dd><dl class="simple">
<dt>{‘best_op_pt’<span class="classifier">best_operating_pt,</span></dt><dd><p>‘precisions’ : precisions,
‘recalls’    : recalls,
‘thresholds’ : thresholds,
‘avg_prec’   : avg_precision
}</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<p>where best_op_pt is:</p>
<blockquote>
<div><dl class="simple">
<dt>{‘threshold’<span class="classifier">&lt;optimal decision probability value&gt;</span></dt><dd><p>‘f1’        : &lt;f1 at the optimal threshold&gt;
‘prec’      : &lt;precision at the optimal threshold&gt;
‘thresholds’ : thresholds,
‘rec’       : &lt;recall at the optimal threshold&gt;
}</p>
</dd>
</dl>
</div></blockquote>
<p>Each of the avg_prec is the 
the average of precisions across the 
samples of one class (AP). I.e. there will
be as many elements in average_precisions
as there are classes.</p>
<p>The Mean Average Precision (mAP) is 
the mean of the average_precision values.
This measure summarizes the family of PR curves.
It is comparable to AUC ROC.</p>
<p>The precisions and recalls returns are dicts.
The keys are class IDs, and the values are the
precisions for that class. They are the quantities
from which the average_precision values are 
computed.</p>
<dl>
<dt>Summary: </dt><dd><dl>
<dt>o precisions/recalls are the lowest granularity</dt><dd><p>of information: the per class precs and recs
at different thresholds.</p>
<p>There are as many entries in these dicts as
there are classes. And prec/rec value pair
from the precisions and recalls dict are results
of one threshold.</p>
<blockquote>
<div><dl>
<dt>TODO: o finish this sentence by running and</dt><dd><blockquote>
<div><p>seeing what’s what</p>
</div></blockquote>
<p>o A unit test for this method
o Finally: the actual drawing of the</p>
<blockquote>
<div><p>curves with pyplot</p>
</div></blockquote>
</dd>
</dl>
</div></blockquote>
</dd>
<dt>o average_precision aggregates the precisions</dt><dd><p>of one class across multiple thresholds. There 
will be as many entries in this dict as there 
are classes.</p>
</dd>
<dt>o mAP aggregates the average_precision values</dt><dd><p>across all classes. This is one number.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>truth_labels</strong> (<em>Tensor</em>) – all truth labels shaped
torch.Size([num-batches, batch-size])</p></li>
<li><p><strong>raw_preds</strong> (<em>Tensor</em>) – the logits for each class for
each sample as 
torch.Shape([num-batches, batch-size, num-classes])</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(precisions, recalls, average_precisions, mAP)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>({int : [floats]}, {int : [floats]}, [floats], float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.fig_from_conf_matrix">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">fig_from_conf_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">conf_matrix</span></em>, <em class="sig-param"><span class="pre">supertitle='Confusion</span> <span class="pre">Matrix\n'</span></em>, <em class="sig-param"><span class="pre">subtitle=''</span></em>, <em class="sig-param"><span class="pre">write_in_fields=&lt;CELL_LABELING.DIAGONAL:</span> <span class="pre">2&gt;</span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.fig_from_conf_matrix" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a confusion matrix, return a 
matplotlib.pyplot Figure with a heatmap of the matrix.</p>
<p>The write_in_fields arg controls whether or not
each cell is filled with a label indicating its
value. If:</p>
<blockquote>
<div><p>o CELL_LABELING.ALWAYS    : always write the labels
o CELL_LABELING.NEVER     : never write the labels
o CELL_LABELING.DIAGONAL  : only label the diagonals
o CELL_LABELING.AUTO      : only write labels if number of classes</p>
<blockquote>
<div><p>is &lt;= CELL_LABELING.AUTO.value</p>
</div></blockquote>
</div></blockquote>
<dl>
<dt>Result form:</dt><dd><blockquote>
<div><p>C_1-pred, C_2-pred, C_3-pred</p>
</div></blockquote>
<p>C_1-true        3         1        0
C_2-true        2         6        1
C_3-true        0         0        3</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conf_matrix</strong> (<em>pd.DataFrame</em>) – nxn confusion matrix representing
rows:truth, cols:predicted for n classes</p></li>
<li><p><strong>supertitle</strong> (<em>str</em>) – main title at top of figure</p></li>
<li><p><strong>subtitle</strong> (<em>str</em>) – title for the confusion matrix
only. Ex: “data normalized to percentages”</p></li>
<li><p><strong>write_in_fields</strong> (<a class="reference internal" href="#result_analysis.charting.CELL_LABELING" title="result_analysis.charting.CELL_LABELING"><em>CELL_LABELING</em></a>) – how many cells, if any should 
contain labels with the cell values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>matplotlib figure with confusion
matrix heatmap.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pyplot.Figure</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.log">
<span class="sig-name descname"><span class="pre">log</span></span><em class="property"> <span class="pre">=</span> <span class="pre">&lt;LoggingService</span> <span class="pre">0x7f9668b70970&gt;</span></em><a class="headerlink" href="#result_analysis.charting.Charter.log" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.read_conf_matrix_from_file">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">read_conf_matrix_from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cm_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.read_conf_matrix_from_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Read a previously computed confusion matrix from
file. Return a dataframe containing the cm.</p>
<p>Depending on the original dataframe/tensor,np_array
from which which the .csv was created, the first line
has a leading comma. This results in:</p>
<blockquote>
<div><blockquote>
<div><p>Unnamed: 0  foo  bar  fum</p>
</div></blockquote>
<p>0        foo    1    2    3
1        bar    4    5    6
2        fum    7    8    9</p>
</div></blockquote>
<p>Rather than the correct:</p>
<blockquote>
<div><blockquote>
<div><p>foo  bar  fum</p>
</div></blockquote>
<p>foo    1    2    3
bar    4    5    6
fum    7    8    9</p>
</div></blockquote>
<p>Since conf matrices are square, we can check
and correct for that.</p>
<dl class="simple">
<dt>NOTE: if arrays of predicted and truth classes are</dt><dd><p>available, rather than an already computed confusion
matrix saved to file, see compute_confusion_matrix().</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cm_path</strong> (<em>str</em>) – path to confusion matrix in csv format</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>confusion matrix as dataframe; no processing on numbers</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>pd.DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="result_analysis.charting.Charter.visualize_testing_result">
<em class="property"><span class="pre">classmethod</span> </em><span class="sig-name descname"><span class="pre">visualize_testing_result</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">truth_labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pred_class_ids</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.Charter.visualize_testing_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Use to visualize results from using a 
saved model on a set of test-set samples.</p>
<p>Draws a PR curve, and adds a table with 
the average precison (AP) of each class.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.CurveSpecification">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">CurveSpecification</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">best_operating_pt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recalls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precisions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">thresholds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">avg_precision</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_id</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.CurveSpecification" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>Instances hold information about one 
classifier evaluation curve. Enough
information is included to draw 
a precision-recall curve.</p>
<blockquote>
<div><dl class="simple">
<dt>best_operating_pt: {‘threshold’<span class="classifier">thresholds[best_op_idx],</span></dt><dd><p>‘f1’        : f1_scores[best_op_idx],
‘prec’      : precisions[best_op_idx],
‘rec’       : recalls[best_op_idx]
}</p>
</dd>
</dl>
<p>recalls          : list of recall values
precisions       : list of precision values
thresholds       : list of probability decision thresholds</p>
<blockquote>
<div><p>at which precions/recall pairs were computed</p>
</div></blockquote>
<p>avg_precision    : the Average Precision (AP) of all the points
class_id         : ID (int or str) for which instances is a curve</p>
</div></blockquote>
<p>The precisions and recalls array-likes form
the x/y pairs when zipped.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.VizConfMatrixReq">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">VizConfMatrixReq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">path</span></em>, <em class="sig-param"><span class="pre">write_in_fields=&lt;CELL_LABELING.DIAGONAL:</span> <span class="pre">2&gt;</span></em>, <em class="sig-param"><span class="pre">supertitle='Confusion</span> <span class="pre">Matrix'</span></em>, <em class="sig-param"><span class="pre">title=''</span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.VizConfMatrixReq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#result_analysis.charting.VizRequest" title="result_analysis.charting.VizRequest"><code class="xref py py-class docutils literal notranslate"><span class="pre">result_analysis.charting.VizRequest</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.VizPRCurvesReq">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">VizPRCurvesReq</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.VizPRCurvesReq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#result_analysis.charting.VizRequest" title="result_analysis.charting.VizRequest"><code class="xref py py-class docutils literal notranslate"><span class="pre">result_analysis.charting.VizRequest</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="result_analysis.charting.VizRequest">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">result_analysis.charting.</span></span><span class="sig-name descname"><span class="pre">VizRequest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#result_analysis.charting.VizRequest" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

</div>
<div class="section" id="module-result_analysis">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-result_analysis" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Team.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>