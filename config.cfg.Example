# Controlling how the classifier training
# runs.

# Boolean quantities may be indicated by
# Yes/No, True/False, 1/0

[Paths]

# Root of the data/test files:
root_train_test_data = /home/data/birds/recombined_data

# Only relevant if running multi-process.
# File showing the distribution of GPUs
# across machines, or within one machine.
# Allows specification of which GPU(s) to
# use on each machine Expected in
# <proj_root>/world_map.json.
# See file world_map.json.Example for
# how to write this configuration

world_map     = ../../world_map.json

# Needed if running multiple processes, and
# therefore using one of the launch scripts.

train_script = birds_train_parallel.py

[Training]

net_name      = resnet18
min_epochs    = 15
max_epochs    = 100
batch_size    = 32
# The 'k' in k=fold cross validation:
num_folds     = 10
seed          = 42
optimizer     = SGD
kernel_size   = 7
lr            = 0.001
momentum      = 0.9
# Training images should be scaled to (in pixels):
sample_width  = 400
sample_height = 400 
verbose       = yes
# Number of seconds between printing status
# to the console, if verbose is 'yes':
show_alive    = 30

[Parallelism]

# Must be the same on all collaborating
# machines:

seed          = 42

# When running distributed, only the master process
# (rank 0) log measurement results. But when
# multiple GPUs are used for independent runs,
# such as for hyperparameter exploration, then
# you want all processes logging their result to
# tensorboard

all_procs_log = False

# Communication used for inter process/machine
# communication during parallel training.
# Any port is OK, one could use 29920, which
# is registered as a Nintendo wifi port.
# 5678 is the default pytorch port:

master_port = 5678
