[Paths]

root_train_test_data = /home/data/birds/recombined_data/

[Training]

net_name      = resnet18
epochs        = 5
batch_size    = 32
seed          = 42
kernel_size   = 7

[Paths]

root_train_test_data = /home/data/birds/recombined_data/

[Training]

net_name      = resnet18
epochs        = 5
batch_size    = 32
seed          = 42
kernel_size   = 7
sample_width  = 400
sample_height = 400


[Parallelism]

# Num of training processes running.
# On each machine: One process per GPU
# on that machine. Or 1 if only CPU is
# available.
#
#    foo.bar.com  = 4
#    127.0.0.1    = 5
#    localhost    = 3
#    172.12.145.1 = 6
#  
# The config parser identifies which of the entries is
# 'localhost' by comparing against local hostname.
# Though 'localhost' or '127.0.0.1' may be provided
# explicitly:

quatro.stanford.edu     = 3
quintus.stanford.edu    = 2

# Communication used for inter process/machine
# communication during parallel training.
# Any port is OK, this is the one registered as
# a Nintendo wifi port:

pytorch_comm_port       = 29920

sample_width  = 400 # pixels
sample_height = 400 # pixels


[Parallelism]

# Num of training processes running.
# On each machine: One process per GPU
# on that machine. Or 1 if only CPU is
# available.
#
#    foo.bar.com  = 4
#    127.0.0.1    = 5
#    localhost    = 3
#    172.12.145.1 = 6
#  
# The config parser identifies which of the entries is
# 'localhost' by comparing against local hostname.
# Though 'localhost' or '127.0.0.1' may be provided
# explicitly:

quatro.stanford.edu     = 3
quintus.stanford.edu    = 2

# Communication used for inter process/machine
# communication during parallel training.
# Any port is OK, this is the one registered as
# a Nintendo wifi port:

pytorch_comm_port       = 29920
